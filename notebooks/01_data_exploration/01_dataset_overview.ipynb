{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Dataset Overview - Fraud Detection Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Objective**: Comprehensive exploration of the fraud detection dataset\\n\",\n",
    "    \"**Author**: Data Science Team\\n\",\n",
    "    \"**Date**: 2025-10-17\\n\",\n",
    "    \"**Version**: 1.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Table of Contents\\n\",\n",
    "    \"1. [Environment Setup](#1-environment-setup)\\n\",\n",
    "    \"2. [Data Loading](#2-data-loading)\\n\",\n",
    "    \"3. [Basic Statistics](#3-basic-statistics)\\n\",\n",
    "    \"4. [Data Quality Assessment](#4-data-quality-assessment)\\n\",\n",
    "    \"5. [Fraud Distribution Analysis](#5-fraud-distribution-analysis)\\n\",\n",
    "    \"6. [Initial Insights](#6-initial-insights)\\n\",\n",
    "    \"7. [Next Steps](#7-next-steps)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Environment Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import plotly.express as px\\n\",\n",
    "    \"import plotly.graph_objects as go\\n\",\n",
    "    \"from plotly.subplots import make_subplots\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Statistical libraries\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"from scipy.stats import chi2_contingency, normaltest\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Data quality libraries\\n\",\n",
    "    \"import pandas_profiling as pp\\n\",\n",
    "    \"import missingno as msno\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Utility libraries\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"from datetime import datetime, timedelta\\n\",\n",
    "    \"from typing import Tuple, List, Dict, Any\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Custom utilities\\n\",\n",
    "    \"sys.path.append('../utils')\\n\",\n",
    "    \"from data_utils import load_fraud_data, clean_data\\n\",\n",
    "    \"from viz_utils import plot_distribution, plot_correlation_matrix\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configuration\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette('husl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set random seed for reproducibility\\n\",\n",
    "    \"np.random.seed(42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üìä Environment setup complete!\\\")\\n\",\n",
    "    \"print(f\\\"Python version: {sys.version}\\\")\\n\",\n",
    "    \"print(f\\\"Pandas version: {pd.__version__}\\\")\\n\",\n",
    "    \"print(f\\\"NumPy version: {np.__version__}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Data Loading\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define data paths\\n\",\n",
    "    \"DATA_PATH = '../data/'\\n\",\n",
    "    \"TRANSACTION_DATA = f'{DATA_PATH}/transactions.csv'\\n\",\n",
    "    \"USER_DATA = f'{DATA_PATH}/users.csv'\\n\",\n",
    "    \"MERCHANT_DATA = f'{DATA_PATH}/merchants.csv'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load datasets\\n\",\n",
    "    \"print(\\\"üîÑ Loading datasets...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    # Load main transaction dataset\\n\",\n",
    "    \"    df_transactions = pd.read_csv(TRANSACTION_DATA, parse_dates=['timestamp'])\\n\",\n",
    "    \"    print(f\\\"‚úÖ Transactions loaded: {df_transactions.shape}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load user data\\n\",\n",
    "    \"    df_users = pd.read_csv(USER_DATA)\\n\",\n",
    "    \"    print(f\\\"‚úÖ Users loaded: {df_users.shape}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load merchant data\\n\",\n",
    "    \"    df_merchants = pd.read_csv(MERCHANT_DATA)\\n\",\n",
    "    \"    print(f\\\"‚úÖ Merchants loaded: {df_merchants.shape}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"except FileNotFoundError as e:\\n\",\n",
    "    \"    print(f\\\"‚ùå File not found: {e}\\\")\\n\",\n",
    "    \"    print(\\\"üìù Creating synthetic data for demonstration...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Generate synthetic data for demonstration\\n\",\n",
    "    \"    from utils.data_utils import generate_synthetic_fraud_data\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    df_transactions, df_users, df_merchants = generate_synthetic_fraud_data(\\n\",\n",
    "    \"        n_transactions=100000,\\n\",\n",
    "    \"        n_users=10000,\\n\",\n",
    "    \"        n_merchants=1000,\\n\",\n",
    "    \"        fraud_rate=0.02\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"‚úÖ Synthetic data generated\\\")\\n\",\n",
    "    \"    print(f\\\"   - Transactions: {df_transactions.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"   - Users: {df_users.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"   - Merchants: {df_merchants.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display basic information about the datasets\\n\",\n",
    "    \"print(\\\"üìã Dataset Overview:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüè¶ TRANSACTIONS DATASET:\\\")\\n\",\n",
    "    \"print(f\\\"Shape: {df_transactions.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Columns: {list(df_transactions.columns)}\\\")\\n\",\n",
    "    \"print(f\\\"Date range: {df_transactions['timestamp'].min()} to {df_transactions['timestamp'].max()}\\\")\\n\",\n",
    "    \"print(f\\\"Memory usage: {df_transactions.memory_usage(deep=True).sum() / 1024**2:.2f} MB\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüë• USERS DATASET:\\\")\\n\",\n",
    "    \"print(f\\\"Shape: {df_users.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Columns: {list(df_users.columns)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüè™ MERCHANTS DATASET:\\\")\\n\",\n",
    "    \"print(f\\\"Shape: {df_merchants.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Columns: {list(df_merchants.columns)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Basic Statistics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display first few rows\\n\",\n",
    "    \"print(\\\"üîç First 5 transactions:\\\")\\n\",\n",
    "    \"display(df_transactions.head())\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìä Data Types:\\\")\\n\",\n",
    "    \"print(df_transactions.dtypes)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìà Descriptive Statistics:\\\")\\n\",\n",
    "    \"display(df_transactions.describe(include='all'))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Fraud distribution analysis\\n\",\n",
    "    \"fraud_counts = df_transactions['is_fraud'].value_counts()\\n\",\n",
    "    \"fraud_rate = df_transactions['is_fraud'].mean()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üö® FRAUD ANALYSIS:\\\")\\n\",\n",
    "    \"print(f\\\"Total transactions: {len(df_transactions):,}\\\")\\n\",\n",
    "    \"print(f\\\"Fraudulent transactions: {fraud_counts[1]:,}\\\")\\n\",\n",
    "    \"print(f\\\"Legitimate transactions: {fraud_counts[0]:,}\\\")\\n\",\n",
    "    \"print(f\\\"Fraud rate: {fraud_rate:.2%}\\\")\\n\",\n",
    "    \"print(f\\\"Class imbalance ratio: {fraud_counts[0] / fraud_counts[1]:.1f}:1\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize fraud distribution\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Pie chart\\n\",\n",
    "    \"fraud_counts.plot(kind='pie', ax=ax1, autopct='%1.2f%%', \\n\",\n",
    "    \"                  labels=['Legitimate', 'Fraudulent'],\\n\",\n",
    "    \"                  colors=['lightgreen', 'salmon'])\\n\",\n",
    "    \"ax1.set_title('Transaction Distribution', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"ax1.set_ylabel('')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Bar chart with counts\\n\",\n",
    "    \"fraud_counts.plot(kind='bar', ax=ax2, color=['lightgreen', 'salmon'])\\n\",\n",
    "    \"ax2.set_title('Transaction Counts', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"ax2.set_xlabel('Transaction Type')\\n\",\n",
    "    \"ax2.set_ylabel('Count')\\n\",\n",
    "    \"ax2.set_xticklabels(['Legitimate', 'Fraudulent'], rotation=0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add count annotations\\n\",\n",
    "    \"for i, v in enumerate(fraud_counts.values):\\n\",\n",
    "    \"    ax2.text(i, v + len(df_transactions)*0.01, f'{v:,}', \\n\",\n",
    "    \"             ha='center', va='bottom', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Data Quality Assessment\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Missing values analysis\\n\",\n",
    "    \"print(\\\"üîç MISSING VALUES ANALYSIS:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*40)\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_values = df_transactions.isnull().sum()\\n\",\n",
    "    \"missing_percentage = (missing_values / len(df_transactions)) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_df = pd.DataFrame({\\n\",\n",
    "    \"    'Column': missing_values.index,\\n\",\n",
    "    \"    'Missing_Count': missing_values.values,\\n\",\n",
    "    \"    'Missing_Percentage': missing_percentage.values\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(missing_df) > 0:\\n\",\n",
    "    \"    display(missing_df)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Visualize missing values\\n\",\n",
    "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"    msno.bar(df_transactions)\\n\",\n",
    "    \"    plt.title('Missing Values by Column', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚úÖ No missing values found in the dataset!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data quality checks\\n\",\n",
    "    \"print(\\\"üîç DATA QUALITY CHECKS:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*30)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check for duplicates\\n\",\n",
    "    \"duplicate_count = df_transactions.duplicated().sum()\\n\",\n",
    "    \"print(f\\\"Duplicate transactions: {duplicate_count}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check for negative amounts\\n\",\n",
    "    \"negative_amounts = (df_transactions['amount'] < 0).sum()\\n\",\n",
    "    \"print(f\\\"Negative amounts: {negative_amounts}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check for future dates\\n\",\n",
    "    \"future_dates = (df_transactions['timestamp'] > datetime.now()).sum()\\n\",\n",
    "    \"print(f\\\"Future timestamps: {future_dates}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check data ranges\\n\",\n",
    "    \"print(f\\\"\\\\nüìä DATA RANGES:\\\")\\n\",\n",
    "    \"print(f\\\"Amount range: ${df_transactions['amount'].min():.2f} - ${df_transactions['amount'].max():,.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Unique users: {df_transactions['user_id'].nunique():,}\\\")\\n\",\n",
    "    \"print(f\\\"Unique merchants: {df_transactions['merchant_id'].nunique():,}\\\")\\n\",\n",
    "    \"print(f\\\"Unique payment methods: {df_transactions['payment_method'].nunique()}\\\")\\n\",\n",
    "    \"print(f\\\"Payment methods: {df_transactions['payment_method'].unique()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Fraud Distribution Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Fraud by amount analysis\\n\",\n",
    "    \"print(\\\"üí∞ FRAUD BY AMOUNT ANALYSIS:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*35)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Amount statistics by fraud status\\n\",\n",
    "    \"amount_stats = df_transactions.groupby('is_fraud')['amount'].agg([\\n\",\n",
    "    \"    'count', 'mean', 'median', 'std', 'min', 'max'\\n\",\n",
    "    \"]).round(2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"amount_stats.index = ['Legitimate', 'Fraudulent']\\n\",\n",
    "    \"display(amount_stats)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize amount distributions\\n\",\n",
    "    \"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Box plot\\n\",\n",
    "    \"df_transactions.boxplot(column='amount', by='is_fraud', ax=ax1)\\n\",\n",
    "    \"ax1.set_title('Amount Distribution by Fraud Status')\\n\",\n",
    "    \"ax1.set_xlabel('Fraud Status (0=Legitimate, 1=Fraudulent)')\\n\",\n",
    "    \"ax1.set_ylabel('Amount ($)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Histogram\\n\",\n",
    "    \"df_transactions[df_transactions['is_fraud'] == 0]['amount'].hist(\\n\",\n",
    "    \"    bins=50, alpha=0.7, label='Legitimate', ax=ax2, density=True)\\n\",\n",
    "    \"df_transactions[df_transactions['is_fraud'] == 1]['amount'].hist(\\n\",\n",
    "    \"    bins=50, alpha=0.7, label='Fraudulent', ax=ax2, density=True)\\n\",\n",
    "    \"ax2.set_title('Amount Distribution Histogram')\\n\",\n",
    "    \"ax2.set_xlabel('Amount ($)')\\n\",\n",
    "    \"ax2.set_ylabel('Density')\\n\",\n",
    "    \"ax2.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Log scale histogram\\n\",\n",
    "    \"legitimate_amounts = df_transactions[df_transactions['is_fraud'] == 0]['amount']\\n\",\n",
    "    \"fraudulent_amounts = df_transactions[df_transactions['is_fraud'] == 1]['amount']\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax3.hist(legitimate_amounts, bins=50, alpha=0.7, label='Legitimate', density=True)\\n\",\n",
    "    \"ax3.hist(fraudulent_amounts, bins=50, alpha=0.7, label='Fraudulent', density=True)\\n\",\n",
    "    \"ax3.set_yscale('log')\\n\",\n",
    "    \"ax3.set_title('Amount Distribution (Log Scale)')\\n\",\n",
    "    \"ax3.set_xlabel('Amount ($)')\\n\",\n",
    "    \"ax3.set_ylabel('Log Density')\\n\",\n",
    "    \"ax3.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Cumulative distribution\\n\",\n",
    "    \"legitimate_sorted = np.sort(legitimate_amounts)\\n\",\n",
    "    \"fraudulent_sorted = np.sort(fraudulent_amounts)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax4.plot(legitimate_sorted, np.linspace(0, 1, len(legitimate_sorted)), \\n\",\n",
    "    \"         label='Legitimate', linewidth=2)\\n\",\n",
    "    \"ax4.plot(fraudulent_sorted, np.linspace(0, 1, len(fraudulent_sorted)), \\n\",\n",
    "    \"         label='Fraudulent', linewidth=2)\\n\",\n",
    "    \"ax4.set_title('Cumulative Distribution of Amounts')\\n\",\n",
    "    \"ax4.set_xlabel('Amount ($)')\\n\",\n",
    "    \"ax4.set_ylabel('Cumulative Probability')\\n\",\n",
    "    \"ax4.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Statistical test for amount differences\\n\",\n",
    "    \"stat, p_value = stats.mannwhitneyu(legitimate_amounts, fraudulent_amounts)\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Mann-Whitney U test for amount differences:\\\")\\n\",\n",
    "    \"print(f\\\"Statistic: {stat:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"P-value: {p_value:.2e}\\\")\\n\",\n",
    "    \"print(f\\\"Result: {'Significant difference' if p_value < 0.05 else 'No significant difference'}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Fraud by payment method\\n\",\n",
    "    \"print(\\\"üí≥ FRAUD BY PAYMENT METHOD:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*30)\\n\",\n",
    "    \"\\n\",\n",
    "    \"payment_fraud = df_transactions.groupby('payment_method')['is_fraud'].agg([\\n\",\n",
    "    \"    'count', 'sum', 'mean'\\n\",\n",
    "    \"]).round(4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"payment_fraud.columns = ['Total_Transactions', 'Fraud_Count', 'Fraud_Rate']\\n\",\n",
    "    \"payment_fraud['Fraud_Percentage'] = payment_fraud['Fraud_Rate'] * 100\\n\",\n",
    "    \"payment_fraud = payment_fraud.sort_values('Fraud_Rate', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(payment_fraud)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize payment method fraud rates\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fraud rate by payment method\\n\",\n",
    "    \"payment_fraud['Fraud_Percentage'].plot(kind='bar', ax=ax1, color='coral')\\n\",\n",
    "    \"ax1.set_title('Fraud Rate by Payment Method', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"ax1.set_xlabel('Payment Method')\\n\",\n",
    "    \"ax1.set_ylabel('Fraud Rate (%)')\\n\",\n",
    "    \"ax1.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Transaction volume by payment method\\n\",\n",
    "    \"payment_fraud['Total_Transactions'].plot(kind='bar', ax=ax2, color='lightblue')\\n\",\n",
    "    \"ax2.set_title('Transaction Volume by Payment Method', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"ax2.set_xlabel('Payment Method')\\n\",\n",
    "    \"ax2.set_ylabel('Number of Transactions')\\n\",\n",
    "    \"ax2.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Initial Insights\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Time-based fraud analysis\\n\",\n",
    "    \"print(\\\"‚è∞ TIME-BASED FRAUD ANALYSIS:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*32)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract time features\\n\",\n",
    "    \"df_transactions['hour'] = df_transactions['timestamp'].dt.hour\\n\",\n",
    "    \"df_transactions['day_of_week'] = df_transactions['timestamp'].dt.day_name()\\n\",\n",
    "    \"df_transactions['month'] = df_transactions['timestamp'].dt.month\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fraud by hour of day\\n\",\n",
    "    \"hourly_fraud = df_transactions.groupby('hour')['is_fraud'].mean() * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fraud by day of week\\n\",\n",
    "    \"daily_fraud = df_transactions.groupby('day_of_week')['is_fraud'].mean() * 100\\n\",\n",
    "    \"daily_fraud = daily_fraud.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', \\n\",\n",
    "    \"                                  'Friday', 'Saturday', 'Sunday'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize temporal patterns\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Hourly patterns\\n\",\n",
    "    \"hourly_fraud.plot(kind='line', marker='o', ax=ax1, color='red', linewidth=2, markersize=6)\\n\",\n",
    "    \"ax1.set_title('Fraud Rate by Hour of Day', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"ax1.set_xlabel('Hour of Day')\\n\",\n",
    "    \"ax1.set_ylabel('Fraud Rate (%)')\\n\",\n",
    "    \"ax1.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Daily patterns\\n\",\n",
    "    \"daily_fraud.plot(kind='bar', ax=ax2, color='orange')\\n\",\n",
    "    \"ax2.set_title('Fraud Rate by Day of Week', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"ax2.set_xlabel('Day of Week')\\n\",\n",
    "    \"ax2.set_ylabel('Fraud Rate (%)')\\n\",\n",
    "    \"ax2.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüîç Key Temporal Insights:\\\")\\n\",\n",
    "    \"print(f\\\"Peak fraud hour: {hourly_fraud.idxmax()}:00 ({hourly_fraud.max():.2f}% fraud rate)\\\")\\n\",\n",
    "    \"print(f\\\"Lowest fraud hour: {hourly_fraud.idxmin()}:00 ({hourly_fraud.min():.2f}% fraud rate)\\\")\\n\",\n",
    "    \"print(f\\\"Highest fraud day: {daily_fraud.idxmax()} ({daily_fraud.max():.2f}% fraud rate)\\\")\\n\",\n",
    "    \"print(f\\\"Lowest fraud day: {daily_fraud.idxmin()} ({daily_fraud.min():.2f}% fraud rate)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Summary insights\\n\",\n",
    "    \"print(\\\"\\\\nüéØ KEY INSIGHTS AND RECOMMENDATIONS:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Dataset Overview:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total transactions: {len(df_transactions):,}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Fraud rate: {fraud_rate:.2%}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Class imbalance: {fraud_counts[0] / fraud_counts[1]:.1f}:1\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüí∞ Financial Impact:\\\")\\n\",\n",
    "    \"total_fraud_amount = df_transactions[df_transactions['is_fraud'] == 1]['amount'].sum()\\n\",\n",
    "    \"avg_fraud_amount = df_transactions[df_transactions['is_fraud'] == 1]['amount'].mean()\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total fraudulent amount: ${total_fraud_amount:,.2f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Average fraud transaction: ${avg_fraud_amount:.2f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüö® Risk Factors Identified:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Higher risk payment method: {payment_fraud.index[0]}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Peak fraud time: {hourly_fraud.idxmax()}:00\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Riskiest day: {daily_fraud.idxmax()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüîß Data Quality:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Missing values: {'Yes' if missing_df.shape[0] > 0 else 'None detected'}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Duplicates: {duplicate_count}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Data anomalies: {negative_amounts + future_dates}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìà Next Steps:\\\")\\n\",\n",
    "    \"print(f\\\"   1. Deep dive into transaction patterns (Notebook 02)\\\")\\n\",\n",
    "    \"print(f\\\"   2. Engineer velocity and behavioral features\\\")\\n\",\n",
    "    \"print(f\\\"   3. Develop baseline models with current features\\\")\\n\",\n",
    "    \"print(f\\\"   4. Focus on class imbalance handling strategies\\\")\\n\",\n",
    "    \"print(f\\\"   5. Investigate high-risk payment methods and times\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"Based on this initial exploration, the recommended next steps are:\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Immediate Actions\\n\",\n",
    "    \"1. **Data Quality**: Address any identified data quality issues\\n\",\n",
    "    \"2. **Feature Engineering**: Create velocity, behavioral, and network features\\n\",\n",
    "    \"3. **Class Imbalance**: Implement SMOTE, undersampling, or cost-sensitive learning\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Analysis Deep Dives\\n\",\n",
    "    \"1. **Transaction Patterns** (`02_transaction_analysis.ipynb`)\\n\",\n",
    "    \"2. **User Behavior Analysis** (`03_fraud_patterns.ipynb`)\\n\",\n",
    "    \"3. **Merchant Risk Assessment** (`04_data_quality_assessment.ipynb`)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Model Development\\n\",\n",
    "    \"1. Start with simple baseline models (Logistic Regression, Decision Trees)\\n\",\n",
    "    \"2. Progress to ensemble methods (Random Forest, XGBoost)\\n\",\n",
    "    \"3. Explore neural networks and anomaly detection approaches\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Business Impact\\n\",\n",
    "    \"1. Calculate fraud prevention ROI\\n\",\n",
    "    \"2. Estimate false positive costs\\n\",\n",
    "    \"3. Develop business-friendly model interpretation\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Next Notebook**: `02_transaction_analysis.ipynb` - Deep dive into transaction patterns and user behavior\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.12.0\"\n",
    "  },\n",
    "  \"toc\": {\n",
    "   \"base_numbering\": 1,\n",
    "   \"nav_menu\": {},\n",
    "   \"number_sections\": true,\n",
    "   \"sideBar\": true,\n",
    "   \"skip_h1_title\": false,\n",
    "   \"title_cell\": \"Table of Contents\",\n",
    "   \"title_sidebar\": \"Contents\",\n",
    "   \"toc_cell\": false,\n",
    "   \"toc_position\": {},\n",
    "   \"toc_section_display\": true,\n",
    "   \"toc_window_display\": true\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
