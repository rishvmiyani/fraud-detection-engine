name: 🤖 Model Training & Deployment

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      data_source:
        description: 'Data source for training'
        required: true
        default: 'production'
        type: choice
        options:
          - 'production'
          - 'staging'
          - 'synthetic'
      model_type:
        description: 'Model type to train'
        required: true
        default: 'all'
        type: choice
        options:
          - 'all'
          - 'xgboost'
          - 'lightgbm'
          - 'neural_network'

env:
  PYTHON_VERSION: '3.12'
  MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}

jobs:
  # 📊 Data Preparation
  data-preparation:
    name: 📊 Data Preparation
    runs-on: ubuntu-latest
    outputs:
      data-hash: ${{ steps.data-hash.outputs.hash }}
      data-size: ${{ steps.data-info.outputs.size }}
      fraud-rate: ${{ steps.data-info.outputs.fraud_rate }}
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
      
      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: 📦 Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pandas numpy scikit-learn
      
      - name: 📊 Generate Training Data
        run: |
          mkdir -p data/training reports
          python -c "
          import pandas as pd
          import numpy as np
          from datetime import datetime, timedelta
          
          # Generate synthetic training data
          np.random.seed(42)
          n_samples = 10000
          
          data = {
              'transaction_id': [f'TXN_{i:08d}' for i in range(n_samples)],
              'user_id': [f'USER_{np.random.randint(1, 1001):04d}' for _ in range(n_samples)],
              'merchant_id': [f'MERCHANT_{np.random.randint(1, 501):03d}' for _ in range(n_samples)],
              'amount': np.random.lognormal(mean=3, sigma=1.5, size=n_samples).round(2),
              'timestamp': [
                  datetime.now() - timedelta(days=np.random.randint(0, 90),
                                           hours=np.random.randint(0, 24),
                                           minutes=np.random.randint(0, 60))
                  for _ in range(n_samples)
              ],
              'payment_method': np.random.choice(['credit_card', 'debit_card', 'paypal'], n_samples),
              'is_fraud': np.random.choice([0, 1], size=n_samples, p=[0.98, 0.02])
          }
          
          df = pd.DataFrame(data)
          df.to_csv('data/training/training_data.csv', index=False)
          print(f'Generated {len(df)} training samples')
          print(f'Fraud rate: {df[\"is_fraud\"].mean():.2%}')
          "
      
      - name: 📊 Calculate Data Hash
        id: data-hash
        run: |
          DATA_HASH=$(md5sum data/training/training_data.csv | cut -d' ' -f1)
          echo "hash=$DATA_HASH" >> $GITHUB_OUTPUT
          echo "Data hash: $DATA_HASH"
      
      - name: 📊 Extract Data Info
        id: data-info
        run: |
          python -c "
          import pandas as pd
          
          df = pd.read_csv('data/training/training_data.csv')
          size = len(df)
          fraud_rate = df['is_fraud'].mean()
          
          print(f'size={size}')
          print(f'fraud_rate={fraud_rate:.4f}')
          " >> $GITHUB_OUTPUT
      
      - name: 📤 Upload Training Data
        uses: actions/upload-artifact@v3
        with:
          name: training-data
          path: data/training/
          retention-days: 7

  # 🤖 Model Training
  model-training:
    name: 🤖 Train Models
    runs-on: ubuntu-latest
    needs: data-preparation
    strategy:
      matrix:
        model: [xgboost, lightgbm, random_forest]
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
      
      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: 📦 Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install xgboost lightgbm scikit-learn joblib
      
      - name: 📥 Download Training Data
        uses: actions/download-artifact@v3
        with:
          name: training-data
          path: data/training/
      
      - name: 🤖 Train Model - ${{ matrix.model }}
        run: |
          mkdir -p models/${{ matrix.model }} reports
          python -c "
          import pandas as pd
          import numpy as np
          from sklearn.model_selection import train_test_split
          from sklearn.ensemble import RandomForestClassifier
          from sklearn.metrics import classification_report, roc_auc_score
          import joblib
          import json
          
          # Load data
          df = pd.read_csv('data/training/training_data.csv')
          
          # Prepare features
          feature_cols = ['amount']
          X = df[feature_cols]
          y = df['is_fraud']
          
          # Split data
          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
          
          # Train model
          if '${{ matrix.model }}' == 'random_forest':
              model = RandomForestClassifier(n_estimators=100, random_state=42)
          else:
              model = RandomForestClassifier(n_estimators=50, random_state=42)  # Fallback
          
          model.fit(X_train, y_train)
          
          # Evaluate
          y_pred = model.predict(X_test)
          y_pred_proba = model.predict_proba(X_test)[:, 1]
          
          metrics = {
              'accuracy': float((y_pred == y_test).mean()),
              'roc_auc': float(roc_auc_score(y_test, y_pred_proba)),
              'model_type': '${{ matrix.model }}'
          }
          
          # Save model and metrics
          joblib.dump(model, 'models/${{ matrix.model }}/model.pkl')
          
          with open('reports/evaluation-${{ matrix.model }}.json', 'w') as f:
              json.dump(metrics, f, indent=2)
          
          print(f'Model ${{ matrix.model }} trained successfully')
          print(f'Accuracy: {metrics[\"accuracy\"]:.4f}')
          print(f'ROC AUC: {metrics[\"roc_auc\"]:.4f}')
          "
      
      - name: 📤 Upload Model Artifacts
        uses: actions/upload-artifact@v3
        with:
          name: model-${{ matrix.model }}
          path: models/${{ matrix.model }}/
      
      - name: 📤 Upload Model Reports
        uses: actions/upload-artifact@v3
        with:
          name: model-reports
          path: reports/

  # 🏆 Model Selection
  model-selection:
    name: 🏆 Model Selection
    runs-on: ubuntu-latest
    needs: [data-preparation, model-training]
    outputs:
      best-model: ${{ steps.select-model.outputs.best_model }}
      best-score: ${{ steps.select-model.outputs.best_score }}
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
      
      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: 📥 Download Model Reports
        uses: actions/download-artifact@v3
        with:
          name: model-reports
          path: reports/
      
      - name: 🏆 Select Best Model
        id: select-model
        run: |
          python -c "
          import json
          import os
          
          models = ['xgboost', 'lightgbm', 'random_forest']
          best_score = 0
          best_model = 'random_forest'
          
          for model in models:
              file_path = f'reports/evaluation-{model}.json'
              if os.path.exists(file_path):
                  with open(file_path, 'r') as f:
                      metrics = json.load(f)
                  if metrics['roc_auc'] > best_score:
                      best_score = metrics['roc_auc']
                      best_model = model
          
          print(f'best_model={best_model}')
          print(f'best_score={best_score:.4f}')
          
          result = {'best_model': best_model, 'best_score': best_score}
          with open('best-model-selection.json', 'w') as f:
              json.dump(result, f)
          " >> $GITHUB_OUTPUT
      
      - name: 📤 Upload Selection Report
        uses: actions/upload-artifact@v3
        with:
          name: model-selection
          path: best-model-selection.json

  # 📧 Training Report
  training-report:
    name: 📧 Training Report
    runs-on: ubuntu-latest
    needs: [data-preparation, model-selection]
    if: always()
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
      
      - name: 📊 Generate Training Report
        run: |
          echo "# 🤖 Model Training Report" > training-report.md
          echo "" >> training-report.md
          echo "## 📊 Data Summary" >> training-report.md
          echo "- Data size: ${{ needs.data-preparation.outputs.data-size }}" >> training-report.md
          echo "- Fraud rate: ${{ needs.data-preparation.outputs.fraud-rate }}" >> training-report.md
          echo "" >> training-report.md
          echo "## 🏆 Best Model" >> training-report.md
          echo "- Model: ${{ needs.model-selection.outputs.best-model }}" >> training-report.md
          echo "- Score: ${{ needs.model-selection.outputs.best-score }}" >> training-report.md
          echo "" >> training-report.md
          echo "**Training completed successfully!** ✅" >> training-report.md
      
      - name: 📱 Slack Notification
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#ml-model-updates'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          custom_payload: |
            {
              "text": "🤖 Model Training Completed",
              "attachments": [{
                "color": "${{ job.status == 'success' && 'good' || 'danger' }}",
                "fields": [{
                  "title": "Best Model",
                  "value": "${{ needs.model-selection.outputs.best-model }}",
                  "short": true
                }, {
                  "title": "Performance Score",
                  "value": "${{ needs.model-selection.outputs.best-score }}",
                  "short": true
                }, {
                  "title": "Data Size",
                  "value": "${{ needs.data-preparation.outputs.data-size }}",
                  "short": true
                }, {
                  "title": "Fraud Rate",
                  "value": "${{ needs.data-preparation.outputs.fraud-rate }}",
                  "short": true
                }]
              }]
            }
        if: always()
